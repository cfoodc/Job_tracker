#!/usr/bin/env python3
"""
Anduril å°åŒ—/æ±äº¬è·ç¼ºè‡ªå‹•åŒæ­¥è…³æœ¬
è‡ªå‹•æŠ“å– Anduril è·ç¼ºé é¢ä¸¦æ›´æ–°åˆ° Notion è³‡æ–™åº«
"""

import os
import re
import json
import requests
from datetime import datetime
from bs4 import BeautifulSoup
from notion_client import Client

# è¨­å®š
GREENHOUSE_API_BASE = "https://boards-api.greenhouse.io/v1/boards/andurilindustries/jobs"

# è¦è¿½è¹¤çš„åœ°é»é—œéµå­—ï¼ˆä¸å€åˆ†å¤§å°å¯«ï¼‰
TARGET_LOCATIONS = {
    "taipei": "Taipei Taiwan",
    "taiwan": "Taipei Taiwan",
    "tokyo": "Tokyo Japan",
    "japan": "Tokyo Japan",
}

# å¾ç’°å¢ƒè®Šæ•¸è®€å–
NOTION_API_KEY = os.environ.get("NOTION_API_KEY")
NOTION_DATABASE_ID = os.environ.get("NOTION_DATABASE_ID")


def get_jobs_from_greenhouse():
    """å¾ Greenhouse API ç²å–è·ç¼ºåˆ—è¡¨ï¼ˆå„ªåŒ–æµé‡ç‰ˆæœ¬ï¼‰"""
    jobs = []

    try:
        # æ­¥é©Ÿ 1: å…ˆç²å–è·ç¼ºåˆ—è¡¨ï¼ˆä¸å«è©³ç´°å…§å®¹ï¼‰- ç¯€çœæµé‡
        print("ğŸ“‹ æ­£åœ¨ç²å–è·ç¼ºåˆ—è¡¨...")
        response = requests.get(GREENHOUSE_API_BASE)
        response.raise_for_status()
        data = response.json()
        
        all_jobs = data.get("jobs", [])
        print(f"ğŸ“Š API å›å‚³ {len(all_jobs)} å€‹è·ç¼º")

        # æ­¥é©Ÿ 2: ç¯©é¸å‡ºç›®æ¨™åœ°å€çš„è·ç¼º
        target_job_ids = []
        target_job_basic = []
        
        for job in all_jobs:
            location = job.get("location", {}).get("name", "")
            location_lower = location.lower()
            
            # æª¢æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•ç›®æ¨™åœ°é»
            if any(keyword in location_lower for keyword in TARGET_LOCATIONS.keys()):
                target_job_ids.append(job.get("id"))
                target_job_basic.append(job)
        
        print(f"ğŸ¯ æ‰¾åˆ° {len(target_job_ids)} å€‹ç›®æ¨™åœ°å€è·ç¼º")

        # æ­¥é©Ÿ 3: åªç²å–ç›®æ¨™è·ç¼ºçš„è©³ç´°å…§å®¹
        for i, job_id in enumerate(target_job_ids, 1):
            try:
                print(f"  ğŸ“¥ æ­£åœ¨ç²å–è·ç¼º {i}/{len(target_job_ids)} çš„è©³ç´°å…§å®¹...")
                detail_response = requests.get(f"{GREENHOUSE_API_BASE}/{job_id}")
                detail_response.raise_for_status()
                job_detail = detail_response.json()
                
                # å–å¾—åŸºæœ¬è³‡è¨Š
                basic_info = target_job_basic[i-1]
                location = basic_info.get("location", {}).get("name", "")
                
                # è§£æè·ç¼ºå…§å®¹
                content = job_detail.get("content", "")
                soup = BeautifulSoup(content, "html.parser")

                # æå–å„å€æ®µ
                about_job = extract_section(soup, ["about the job", "about the team"])
                what_youll_do = extract_section(soup, ["what you'll do", "what you will do"])
                required_quals = extract_section(soup, ["required qualifications", "requirements"])
                preferred_quals = extract_section(soup, ["preferred qualifications", "nice to have"])

                # æå–ç¶“é©—è¦æ±‚
                experience = extract_experience(required_quals)

                # æå–éƒ¨é–€
                departments = job_detail.get("departments", [])
                department = departments[0].get("name", "Unknown") if departments else "Unknown"

                jobs.append({
                    "id": str(job_detail.get("id", "")),
                    "title": job_detail.get("title", ""),
                    "location": location,
                    "department": department,
                    "apply_url": job_detail.get("absolute_url", ""),
                    "experience": experience,
                    "about_job": about_job,
                    "what_youll_do": what_youll_do,
                    "required_qualifications": required_quals,
                    "preferred_qualifications": preferred_quals,
                    "updated_at": job_detail.get("updated_at", ""),
                })
                
            except Exception as e:
                print(f"  âš ï¸ ç²å–è·ç¼º {job_id} è©³ç´°å…§å®¹å¤±æ•—: {e}")
                continue

        print(f"âœ… æˆåŠŸç²å– {len(jobs)} å€‹è·ç¼ºï¼ˆå°åŒ—/æ±äº¬ï¼‰")
        return jobs

    except Exception as e:
        print(f"âŒ ç²å–è·ç¼ºå¤±æ•—: {e}")
        return []


def extract_section(soup, keywords):
    """å¾ HTML ä¸­æå–ç‰¹å®šå€æ®µ"""
    text = soup.get_text()

    for keyword in keywords:
        pattern = rf"{keyword}[:\s]*(.*?)(?=(?:what you|required|preferred|about|$))"
        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
        if match:
            return match.group(1).strip()[:2000]  # é™åˆ¶é•·åº¦

    return ""


def extract_experience(text):
    """å¾æ–‡å­—ä¸­æå–ç¶“é©—å¹´æ•¸è¦æ±‚"""
    if not text:
        return "æœªæŒ‡å®š"

    # å°‹æ‰¾ X+ years æ ¼å¼
    match = re.search(r"(\d+)\+?\s*years?", text, re.IGNORECASE)
    if match:
        return f"{match.group(1)}+ years"

    return "æœªæŒ‡å®š"


def get_existing_jobs_from_notion(notion, database_id):
    """ç²å– Notion è³‡æ–™åº«ä¸­ç¾æœ‰çš„è·ç¼º"""
    existing = {}

    try:
        results = notion.databases.query(database_id=database_id)

        for page in results.get("results", []):
            props = page.get("properties", {})

            # ç²å– REQ ID ä½œç‚ºå”¯ä¸€è­˜åˆ¥ç¬¦
            req_id_prop = props.get("REQ ID", {})
            rich_text = req_id_prop.get("rich_text", [])
            if rich_text and len(rich_text) > 0:
                req_id = rich_text[0].get("text", {}).get("content", "")
                if req_id:
                    existing[req_id] = {
                        "page_id": page["id"],
                        "properties": props
                    }

        print(f"ğŸ“‹ Notion ä¸­ç¾æœ‰ {len(existing)} å€‹è·ç¼º")
        return existing

    except Exception as e:
        print(f"âŒ ç²å– Notion è³‡æ–™å¤±æ•—: {e}")
        return {}


def create_job_page(notion, database_id, job):
    """åœ¨ Notion å»ºç«‹æ–°è·ç¼ºé é¢"""

    # æº–å‚™å±¬æ€§
    properties = {
        "è·ä½åç¨±": {"title": [{"text": {"content": job["title"]}}]},
        "éƒ¨é–€": {"select": {"name": normalize_department(job["department"])}},
        "åœ°é»": {"select": {"name": normalize_location(job["location"])}},
        "REQ ID": {"rich_text": [{"text": {"content": job["id"]}}]},
        "ç¶“é©—è¦æ±‚": {"rich_text": [{"text": {"content": job["experience"]}}]},
        "ç”³è«‹é€£çµ": {"url": job["apply_url"]},
        "è·ç¼ºæè¿°æ‘˜è¦": {"rich_text": [{"text": {"content": job["about_job"][:2000] if job["about_job"] else ""}}]},
        "ç”³è«‹ç‹€æ…‹": {"select": {"name": "å°šæœªç”³è«‹"}},
        "æ–°å¢æ—¥æœŸ": {"date": {"start": datetime.now().strftime("%Y-%m-%d")}},
    }

    # å»ºç«‹é é¢å…§å®¹
    content = build_page_content(job)

    try:
        # å»ºç«‹é é¢
        page = notion.pages.create(
            parent={"database_id": database_id},
            properties=properties,
            children=content
        )
        print(f"  âœ… æ–°å¢: {job['title']}")
        return page

    except Exception as e:
        print(f"  âŒ æ–°å¢å¤±æ•— {job['title']}: {e}")
        return None


def update_job_page(notion, page_id, job):
    """æ›´æ–°ç¾æœ‰è·ç¼ºé é¢"""

    content = build_page_content(job)

    try:
        # æ›´æ–°é é¢å…§å®¹
        # å…ˆåˆªé™¤ç¾æœ‰å…§å®¹
        existing_blocks = notion.blocks.children.list(block_id=page_id)
        for block in existing_blocks.get("results", []):
            notion.blocks.delete(block_id=block["id"])

        # åŠ å…¥æ–°å…§å®¹
        notion.blocks.children.append(block_id=page_id, children=content)
        print(f"  ğŸ”„ æ›´æ–°: {job['title']}")

    except Exception as e:
        print(f"  âŒ æ›´æ–°å¤±æ•— {job['title']}: {e}")


def build_page_content(job):
    """å»ºç«‹ Notion é é¢å…§å®¹å€å¡Š"""
    blocks = []

    # About the Job
    if job.get("about_job"):
        blocks.append({"heading_1": {"rich_text": [{"text": {"content": "About the Job"}}]}})
        blocks.append({"paragraph": {"rich_text": [{"text": {"content": job["about_job"][:2000]}}]}})

    # What You'll Do
    if job.get("what_youll_do"):
        blocks.append({"heading_1": {"rich_text": [{"text": {"content": "What You'll Do"}}]}})
        blocks.append({"paragraph": {"rich_text": [{"text": {"content": job["what_youll_do"][:2000]}}]}})

    # Required Qualifications
    if job.get("required_qualifications"):
        blocks.append({"heading_1": {"rich_text": [{"text": {"content": "Required Qualifications"}}]}})
        blocks.append({"paragraph": {"rich_text": [{"text": {"content": job["required_qualifications"][:2000]}}]}})

    # Preferred Qualifications
    if job.get("preferred_qualifications"):
        blocks.append({"heading_1": {"rich_text": [{"text": {"content": "Preferred Qualifications"}}]}})
        blocks.append({"paragraph": {"rich_text": [{"text": {"content": job["preferred_qualifications"][:2000]}}]}})

    # æœ€å¾Œæ›´æ–°æ™‚é–“
    blocks.append({"divider": {}})
    blocks.append({
        "paragraph": {
            "rich_text": [{"text": {"content": f"ğŸ”„ æœ€å¾ŒåŒæ­¥: {datetime.now().strftime('%Y-%m-%d %H:%M')}"}}],
            "color": "gray"
        }
    })

    return blocks


def normalize_department(dept):
    """æ¨™æº–åŒ–éƒ¨é–€åç¨±"""
    dept_lower = dept.lower()

    if "test" in dept_lower or "electrical" in dept_lower:
        return "Electrical Test Engineering"
    elif "business" in dept_lower or "bd" in dept_lower:
        return "Business Development"
    else:
        return dept[:100]  # Notion é™åˆ¶


def normalize_location(location):
    """æ¨™æº–åŒ–åœ°é»åç¨±"""
    location_lower = location.lower()
    
    # æ ¹æ“šé—œéµå­—æ˜ å°„åˆ°æ¨™æº–åœ°é»åç¨±
    for keyword, standard_name in TARGET_LOCATIONS.items():
        if keyword in location_lower:
            return standard_name
    
    # å¦‚æœæ²’æœ‰åŒ¹é…ï¼Œè¿”å›åŸå§‹åœ°é»ï¼ˆæˆªæ–·ï¼‰
    return location[:100]  # Notion é™åˆ¶


def mark_removed_jobs(notion, existing_jobs, current_job_ids):
    """æ¨™è¨˜å·²ç§»é™¤çš„è·ç¼º"""
    for req_id, data in existing_jobs.items():
        if req_id not in current_job_ids:
            try:
                # æ›´æ–°å‚™è¨»æ¬„ä½
                notion.pages.update(
                    page_id=data["page_id"],
                    properties={
                        "å‚™è¨»": {"rich_text": [{"text": {"content": f"âš ï¸ è·ç¼ºå¯èƒ½å·²é—œé–‰ ({datetime.now().strftime('%Y-%m-%d')})"}}]}
                    }
                )
                print(f"  âš ï¸ æ¨™è¨˜å·²é—œé–‰: REQ ID {req_id}")
            except Exception as e:
                print(f"  âŒ æ¨™è¨˜å¤±æ•—: {e}")


def main():
    """ä¸»ç¨‹å¼"""
    print("=" * 50)
    print("ğŸš€ Anduril å°åŒ—/æ±äº¬è·ç¼ºåŒæ­¥é–‹å§‹")
    print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)

    # é©—è­‰ç’°å¢ƒè®Šæ•¸
    if not NOTION_API_KEY:
        print("âŒ éŒ¯èª¤: è«‹è¨­å®š NOTION_API_KEY ç’°å¢ƒè®Šæ•¸")
        return 1

    if not NOTION_DATABASE_ID:
        print("âŒ éŒ¯èª¤: è«‹è¨­å®š NOTION_DATABASE_ID ç’°å¢ƒè®Šæ•¸")
        return 1

    # åˆå§‹åŒ– Notion client
    notion = Client(auth=NOTION_API_KEY)

    # ç²å–æœ€æ–°è·ç¼º
    jobs = get_jobs_from_greenhouse()
    if not jobs:
        print("âš ï¸ æ²’æœ‰æ‰¾åˆ°å°åŒ—/æ±äº¬è·ç¼ºï¼Œå˜—è©¦å‚™ç”¨æ–¹æ³•...")
        # å¯ä»¥åŠ å…¥å‚™ç”¨æŠ“å–æ–¹æ³•

    # ç²å–ç¾æœ‰ Notion è³‡æ–™
    existing_jobs = get_existing_jobs_from_notion(notion, NOTION_DATABASE_ID)

    # åŒæ­¥è·ç¼º
    current_req_ids = set()
    for job in jobs:
        req_id = job["id"]
        current_req_ids.add(req_id)

        if req_id in existing_jobs:
            # æ›´æ–°ç¾æœ‰è·ç¼º
            update_job_page(notion, existing_jobs[req_id]["page_id"], job)
        else:
            # æ–°å¢è·ç¼º
            create_job_page(notion, NOTION_DATABASE_ID, job)

    # æ¨™è¨˜å·²ç§»é™¤çš„è·ç¼º
    mark_removed_jobs(notion, existing_jobs, current_req_ids)

    print("=" * 50)
    print("âœ… åŒæ­¥å®Œæˆ!")
    print("=" * 50)

    return 0


if __name__ == "__main__":
    exit(main())
